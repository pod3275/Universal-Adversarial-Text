# Universal-Adversarial-Text

## 1. 설명

  - 주어진 NLP 모델에 대해 단 하나의 perturbation 문장을 생성함으로써 모델을 속이는 universal adversarial attack 기법.
  - Universal adversarial attack에 의해 생성되는 문장은 입력 문장에 추가되고, 이로 인해 문장의 분류 결과는 기존과 다르게 나타남.
  - 제안 기법은 baseline 기법에 비해 약간 좋은 성능을 나타내고, 보다 효율적으로 attack을 수행할 수 있음.

## 2. 모델 구조

  ![image](https://user-images.githubusercontent.com/26705935/50680219-3be50580-104a-11e9-9473-847d96b42dd9.png)
  
## 3. 실험 결과
